@context{domain:health_dashboard, feature:data_deduplication, version:1.0}

#ROOT
  ##dataDeduplication{id:dedup_system, type:feature, @critical}
    "Health data deduplication service to prevent duplicate entries"
    
    ##dataFlowTrace{id:complete_cycle, type:workflow, @critical}
      "Complete deduplication workflow"
      
      ##triggerPoints{id:dedup_triggers, type:entry_points}
        "When deduplication occurs"
        @cluster{triggers, type:activation}
          "During health data import"
          "Batch data insertion"
          "Native health sync"
          "Manual data entry"
        @/cluster
      
      ##deduplicationFlow{id:dedup_process, type:layer, @sequential}
        "Deduplication processing flow"
        
        ##dataIdentification{id:duplicate_detection}
          "Identify potential duplicates"
          @processing{
            strategy:"Multi-factor matching",
            factors:[
              "dataType exact match",
              "timestamp proximity (±1 minute)",
              "value similarity",
              "source device"
            ]
          }
        
        ##hashGeneration{id:unique_hash}
          "Generate unique hash for records"
          @processing{
            algorithm:"SHA-256",
            inputs:[
              "userId",
              "dataType", 
              "normalizedTimestamp",
              "roundedValue"
            ],
            purpose:"Fast duplicate lookup"
          }
        
        ##existingDataQuery{id:database_check}
          "Check for existing records"
          @cluster{queries, type:database}
            "Query by hash (primary)"
            "Query by timestamp range"
            "Query by dataType and value"
            "Source-based filtering"
          @/cluster
        
        ##conflictResolution{id:duplicate_handling}
          "Resolve duplicate conflicts"
          @cluster{strategies, type:resolution}
            "Keep higher precision value"
            "Prefer device source over manual"
            "Merge metadata fields"
            "Update timestamp to earliest"
          @/cluster
    
    ##deduplicationService{id:service_implementation, type:layer}
      "Deduplication service architecture"
      
      ##serviceStructure{id:dedup_service}
        "HealthDataDeduplicationService"
        @file{path:"server/services/health-data-deduplication.ts"}
        @cluster{methods, type:api}
          "deduplicateBatch(records[])"
          "generateRecordHash(record)"
          "findDuplicates(record)"
          "resolveConflicts(existing, new)"
        @/cluster
      
      ##cacheLayer{id:dedup_cache}
        "In-memory deduplication cache"
        @processing{
          structure:"LRU cache",
          key:"Record hash",
          ttl:"5 minutes",
          purpose:"Fast duplicate checking"
        }
      
      ##batchProcessing{id:batch_dedup}
        "Batch deduplication optimization"
        @processing{
          strategy:"Process in chunks",
          chunkSize:"100 records",
          parallelization:"Worker threads",
          memory:"Streaming for large sets"
        }
    
    ##algorithmDetails{id:dedup_algorithms, type:logic}
      "Deduplication algorithms"
      
      ##timestampNormalization{id:time_rounding}
        "Normalize timestamps for matching"
        @processing{
          rounding:"Nearest minute",
          timezone:"UTC conversion",
          drift:"Account for device clock drift",
          range:"±60 seconds window"
        }
      
      ##valueNormalization{id:value_rounding}
        "Normalize values for comparison"
        @cluster{normalization, type:rules}
          "Decimal precision rounding"
          "Unit conversion before compare"
          "Percentage tolerance (±0.1%)"
          "Special handling for zero"
        @/cluster
      
      ##sourceHierarchy{id:source_priority}
        "Source reliability hierarchy"
        @cluster{priority_order, type:ranking}
          "1. Medical devices (highest)"
          "2. Fitness trackers"
          "3. Phone sensors"
          "4. Manual entry (lowest)"
        @/cluster
    
    ##performanceOptimizations{id:performance, type:optimization}
      "Deduplication performance strategies"
      
      ##indexing{id:database_indexes}
        "Database index optimization"
        @cluster{indexes, type:database}
          "Composite index (userId, dataType, timestamp)"
          "Hash index for quick lookup"
          "Partial index for recent data"
          "Source-based filtering index"
        @/cluster
      
      ##queryOptimization{id:efficient_queries}
        "Optimize duplicate queries"
        @cluster{strategies, type:sql}
          "Prepared statements"
          "Batch WHERE IN queries"
          "Time range partitioning"
          "Result set limiting"
        @/cluster
      
      ##memoryManagement{id:memory_efficiency}
        "Memory-efficient processing"
        @cluster{techniques, type:memory}
          "Stream processing for large files"
          "Garbage collection hints"
          "WeakMap for temporary data"
          "Chunk-based processing"
        @/cluster
    
    ##errorHandling{id:error_boundaries, type:reliability}
      "Deduplication error handling"
      
      ##dataIntegrity{id:integrity_errors}
        @cluster{handling, type:errors}
          "Hash collision handling"
          "Corrupt data detection"
          "Missing field handling"
          "Type mismatch recovery"
        @/cluster
      
      ##performanceErrors{id:resource_errors}
        @cluster{handling, type:errors}
          "Memory limit protection"
          "Query timeout handling"
          "Cache overflow management"
          "Batch size adjustment"
        @/cluster
    
    ##integrationEvidence{id:verified_integration, type:validation}
      "Deduplication integration verification"
      
      ##serviceFile{id:dedup_service}
        @evidence{
          file:"server/services/health-data-deduplication.ts",
          exists:true,
          purpose:"Main deduplication service"
        }
      
      ##importIntegration{id:import_usage}
        @evidence{
          description:"Called during health data import",
          process:"Before batch insertion",
          purpose:"Prevent duplicate storage"
        }
      
      ##performanceMetrics{id:dedup_efficiency}
        @evidence{
          metrics:[
            "Sub-50ms per record",
            "99% duplicate detection rate",
            "Minimal false positives"
          ]
        }
    
    ##dependencies{id:feature_dependencies, type:graph}
      "Deduplication dependencies"
      
      ##dataDependencies{id:data_requirements}
        @cluster{requirements, type:dependency}
          "Health data schema"
          "Database connection"
          "Hash generation library"
          "Cache implementation"
        @/cluster
      
      ##serviceDependencies{id:integration_deps}
        @cluster{services, type:dependency}
          "Storage service"
          "Import pipeline"
          "Validation service"
          "Logging service"
        @/cluster
    
    ##impacts{id:affected_features, type:graph}
      "Features impacted by deduplication"
      
      ##dataQuality{id:quality_improvement}
        @cluster{effects, type:impact}
          "Cleaner health data"
          "Accurate trend analysis"
          "Reduced storage usage"
          "Better performance"
        @/cluster
      
      ##userExperience{id:ux_benefits}
        @cluster{effects, type:impact}
          "No duplicate entries shown"
          "Accurate metrics"
          "Consistent dashboards"
          "Reliable reports"
        @/cluster