@context{domain:chat, feature:message_streaming}
@meta{
  featureName:"message-streaming",
  featureGroup:"core-messaging", 
  parentFile:"./chat-domain.shdl",
  domain:"chat",
  lastUpdated:"2025-01-01T00:00:00Z",
  mappingVersion:"2.0.0"
}

#ROOT
  ##messageStreaming{id:message_streaming_feature, type:complete_mapping, @comprehensive}
    "ChatGPT-style real-time streaming with natural typing rhythm"
    
    ##userFlow{id:user_workflow, type:user_journey, @sequential}
      "User experience for message streaming"
      @processing{
        step1:"User sends message and sees immediate response",
        step2:"AI thinking indicator appears briefly",
        step3:"Response text streams character by character", 
        step4:"Natural pauses at punctuation marks",
        step5:"Smooth cursor animation during streaming"
      }
    
    ##systemFlow{id:system_workflow, type:system_processing, @sequential}
      "System implementation of streaming functionality"
      @processing{
        process1:"Establish Server-Sent Events (SSE) connection",
        process2:"Stream AI response chunks from provider",
        process3:"Process chunks through streaming pipeline",
        process4:"Apply natural timing variations",
        process5:"Update UI state per character/word"
      }
    
    ##dataFlowTrace{id:data_flow, type:request_response, @critical}
      "Complete streaming data flow from server to UI"
      
      ##userAction{id:trigger, type:interaction, @blocking}
        "Message sent triggers streaming response"
        @processing{send_message→start_streaming}
      
      ##frontendFlow{id:client_processing, type:layer, @sequential}
        "Client-side streaming state management"
        
        ##triggerComponent{id:initiator}
          "useStreamingChat hook manages streaming"
          @ref:useStreamingChat.ts
        
        ##eventHandlers{id:handlers}
          @cluster{functions, type:handlers}
            "startStreaming - Initiates SSE connection",
            "handleStreamEvent - Processes SSE events",
            "stopStreaming - Cleanup on completion"
          @/cluster
        
        ##stateChanges{id:react_state}
          @cluster{updates, type:react_state}
            "streamingMessage state per chunk",
            "isThinking toggle for AI status",
            "isConnected for connection state",
            "pendingUserMessage tracking"
          @/cluster
        
        ##reactQueryHooks{id:query_system}
          @cluster{hooks, type:tanstack_query}
            "Optimistic message updates",
            "No query invalidation during stream"
          @/cluster
        
        ##apiCalls{id:network_requests, @critical}
          "SSE connection for streaming"
          @processing{
            endpoint:"/api/messages/stream",
            method:"POST",
            responseType:"text/event-stream"
          }
          @cluster{sseEvents, type:stream_events}
            "data: {type: 'start'}",
            "data: {type: 'thinking'}",
            "data: {type: 'chunk', content: '...'}",
            "data: {type: 'complete', fullResponse: '...'}",
            "data: {type: 'done'}"
          @/cluster
      
      ##networkLayer{id:transport, type:layer}
        "Server-Sent Events transport layer"
        @processing{
          protocol:"HTTP/1.1 with chunked transfer",
          headers:{
            "Content-Type":"text/event-stream",
            "Cache-Control":"no-cache",
            "Connection":"keep-alive"
          }
        }
        @cluster{streamingFeatures, type:sse}
          "Automatic reconnection",
          "Event ID tracking",
          "Heartbeat messages"
        @/cluster
      
      ##backendFlow{id:server_processing, type:layer, @sequential}
        "Server-side streaming implementation"
        
        ##routeHandler{id:entry_point}
          "chat-routes.ts streaming endpoint"
          @ref:app.post('/api/messages/stream')
        
        ##servicesCalled{id:business_logic}
          @cluster{services, type:business_logic}
            "aiService.getChatResponseStream",
            "Chunk callback for real-time streaming",
            "Error callback for stream failures"
          @/cluster
        
        ##externalApiCalls{id:third_party}
          @cluster{external_services, type:api_calls}
            "OpenAI streaming API",
            "Google AI streaming API"
          @/cluster
          @cluster{streaming_implementation, type:provider_specific}
            "OpenAI: EventSource with chunks",
            "Google: generateContentStream"
          @/cluster
        
        ##streamProcessing{id:chunk_handling, @critical}
          "Real-time chunk processing"
          @cluster{chunkFlow, type:processing}
            "Receive chunk from AI provider",
            "Extract content from chunk",
            "Write SSE event to response",
            "Flush response buffer"
          @/cluster
      
      ##responseFlow{id:response_processing, type:layer, @sequential}
        "SSE event stream to client"
        @cluster{eventTypes, type:sse_events}
          "start - Stream initiated",
          "thinking - AI processing",
          "user_message_saved - DB confirmation",
          "ai_model_selected - Model info",
          "chunk - Content fragment",
          "complete - Full response",
          "done - Stream complete",
          "error - Stream failure"
        @/cluster
        @processing{
          chunkSize:"Variable (1-100 chars)",
          flushFrequency:"Immediate per chunk"
        }
      
      ##frontendUpdateFlow{id:ui_refresh, type:layer}
        "Real-time UI updates during streaming"
        @cluster{streamingComponent, type:ui_component}
          "SmoothStreamingText component",
          "Character-by-character rendering",
          "Natural timing variations"
        @/cluster
        @cluster{visualEffects, type:animations}
          "Animated cursor with fade effects",
          "Streaming container glow",
          "Smooth text appearance"
        @/cluster
        @cluster{stateSync, type:state_management}
          "Accumulate chunks in streamingMessage",
          "Update optimistic message per chunk",
          "Preserve message on completion"
        @/cluster

    ##architecturalLayers{id:architecture, type:dependency_analysis}
      "Streaming architecture components"
      
      ##presentation{id:frontend_layer, type:ui_layer}
        ##components{id:ui_components, @critical}
          @cluster{primary, type:main_features}
            "SmoothStreamingText.tsx - Animated text display",
            "MessageDisplayArea.tsx - Container component"
          @/cluster
          @cluster{supporting, type:helpers}
            "StreamingText.tsx - Fallback component",
            "chat-message.tsx - Message wrapper"
          @/cluster
        
        ##hooks{id:custom_hooks}
          @cluster{react_hooks, type:state_logic}
            "useStreamingChat - SSE management",
            "useAppContext - Global state sync"
          @/cluster
        
        ##animations{id:streaming_animations}
          @cluster{css_animations, type:styling}
            "chatgpt-cursor-blink - Cursor animation",
            "messageAppear - Message fade-in",
            "streaming-pulse - Active indicator"
          @/cluster
      
      ##businessLogic{id:backend_layer, type:server_layer}
        ##routes{id:api_routes, @critical}
          @cluster{express_handlers, type:route_handlers}
            "SSE response headers setup",
            "Chunk writing with flush",
            "Connection lifecycle management"
          @/cluster
        
        ##services{id:business_services, @critical}
          @cluster{streaming_services, type:ai_integration}
            "OpenAI streaming implementation",
            "Google AI streaming adapter",
            "Stream error handling"
          @/cluster
      
      ##dataLayer{id:persistence_layer, type:data_layer}
        ##streaming{id:stream_state, @critical}
          "No direct DB interaction during streaming"
          @cluster{async_operations, type:background}
            "Message saved before streaming",
            "AI response saved after completion"
          @/cluster
      
      ##integration{id:external_layer, type:integration_layer}
        ##streamingProtocols{id:streaming_apis}
          @cluster{providers, type:external_streaming}
            "OpenAI: Server-sent events",
            "Google: Streaming generate API"
          @/cluster
          @cluster{features, type:stream_features}
            "Incremental content delivery",
            "Error recovery mid-stream",
            "Token usage tracking"
          @/cluster

    ##performanceConsiderations{id:optimization, type:efficiency_mapping}
      "Streaming performance optimizations"
      
      ##characterTiming{id:typing_rhythm, type:ui_optimization}
        @cluster{baseDelays, type:timing}
          "Regular chars: 15ms base",
          "Spaces: 25ms",
          "Punctuation: 80-150ms",
          "Line breaks: 200ms"
        @/cluster
        @cluster{variations, type:natural_feel}
          "±3-7ms randomization",
          "Context-aware adjustments",
          "Content type adaptation"
        @/cluster
      
      ##streamingModes{id:hybrid_streaming, type:optimization}
        @cluster{modes, type:streaming_strategy}
          "Character mode: <2000 chars",
          "Word mode: >2000 chars",
          "Adaptive switching"
        @/cluster
      
      ##bufferManagement{id:stream_buffering, type:backend_optimization}
        @cluster{buffering, type:performance}
          "No server-side buffering",
          "Immediate chunk flushing",
          "Client-side accumulation"
        @/cluster

    ##securityConsiderations{id:security, type:protection_mapping}
      "Streaming security measures"
      
      ##connectionSecurity{id:stream_security, type:transport_security}
        @cluster{sseProtection, type:security_headers}
          "CORS headers for SSE",
          "Connection timeout limits",
          "Rate limiting per user"
        @/cluster

    ##integrationEvidence{id:validation, type:evidence_tracking}
      ##implementationStatus{id:feature_status, type:status_tracking}
        @processing{
          status:"active",
          lastVerified:"2025-01-01T00:00:00Z",
          verificationMethod:"manual",
          evidenceLocation:"client/src/hooks/useStreamingChat.ts"
        }

    ##dependencies{id:feature_dependencies, type:dependency_tracking}
      @cluster{internal, type:internal_features}
        "Send Message feature",
        "Smooth Streaming Text feature",
        "Optimistic Updates feature"
      @/cluster
      @cluster{external, type:third_party}
        "Server-Sent Events API",
        "AI Provider Streaming APIs"
      @/cluster

    ##impacts{id:feature_impacts, type:impact_analysis}
      @cluster{affects, type:affected_features}
        "Message Display",
        "Natural Timing Variations",
        "Enhanced Cursor Animations"
      @/cluster

@processing{
  mapping_sequence:[userFlow, systemFlow, dataFlowTrace, architecturalLayers],
  quality_gates:[performanceConsiderations, securityConsiderations],
  validation_requirements:[integrationEvidence],
  relationship_analysis:[dependencies, impacts]
}